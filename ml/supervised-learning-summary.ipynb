{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAML 07 - Supervised Learning\n",
    "\n",
    "Michal Grochmal <michal.grochmal@city.ac.uk>\n",
    "\n",
    "Let's have an overview of the supervised learning two main applications and see why these are\n",
    "so useful and important to today's intelligent systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Is so popular because several problems can be thought of as a classification.\n",
    "Notably problems where we want to know if something is or is not an instance of something.\n",
    "Some examples:\n",
    "\n",
    "*   Whether a transaction is or is not a fraud\n",
    "*   Whether an image has a face or has not\n",
    "*   Whether an email is spam or not\n",
    "*   Probability of an iceberg floating in each of three sea currents\n",
    "*   Given the symptoms, if a patient may or may not have certain sickness\n",
    "*   As a bigger example: in a recommendation engine, you may not want to calculate\n",
    "    a score for each product versus each customer, you can classify products as interesting\n",
    "    and not interesting at all, and then calculate a score only on the interesting ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "The final result of a regression is a model that generates continuous numbers,\n",
    "and comparing these generated numbers makes sense.  This outlines the power of\n",
    "the regression techniques: given a set of unknown samples we can **order them**.\n",
    "Examples of regression use follow:\n",
    "\n",
    "*   Estimate the effect of a physics law (possibly proving or disproving a theory)\n",
    "*   Estimate speed limits for roads\n",
    "*   The amount of fish depending on season and weather\n",
    "*   Risk estimation between different courses of action\n",
    "*   In a recommendation engine, the score of recommended items (so we can order them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "There are plethora of ways of evaluating a supervised model.  And it is not possible to create a single\n",
    "evaluation methods for all models because models of different data are inherently different.\n",
    "The way how you evaluate a model depends much more on what data you are working on than what\n",
    "type of model is being used.\n",
    "\n",
    "In classification the F1 score is a pretty good general evaluation in which we make sure that\n",
    "we do not miss certain classes from appearing.  But that evaluation is not a panacea for every\n",
    "classification problem, for example, **fraud and diagnostic classification** need a score in which\n",
    "false negatives weight much more than false positives.\n",
    "\n",
    "Also, most statistical fallacies do apply to machine learning models.  The most seen fallacy that make\n",
    "machine learning models to fail is the base rate fallacy.  This fallacy is very well illustrated by\n",
    "*Alex Reinhart* in his book *Statistics Done Wrong* (see link to full text below):\n",
    "\n",
    "> Suppose 0.8% of women who get mammograms have breast cancer. In 90% of women with breast cancer,\n",
    "> the mammogram will correctly detect it. (That’s the statistical power of the test.\n",
    "> This is an estimate, since it’s hard to tell how many cancers are missed if we don’t know they’re there.)\n",
    "> However, among women with no breast cancer at all, about 7% will get a positive reading on the mammogram,\n",
    "> leading to further tests and biopsies and so on. If you get a positive mammogram result,\n",
    "> what are the chances you have breast cancer?\n",
    ">\n",
    "> Ignoring the chance that you, the reader, are male, the answer is 9%.\n",
    "\n",
    "This could not be more true for machine learning.  More often than not one is faced with datasets\n",
    "in which the prevalence of one class (normally negative, e.g. non-fraud, healthy) over others.\n",
    "It is often better to reduce the dataset and train on a sample where classes do not have orders\n",
    "of magnitude differences in population.  In other words, a dataset is often as good (and as big)\n",
    "as the number of samples of the smaller class in the data.  You cannot train a classifier\n",
    "to recognize Van Gogh paintings by giving it 1 Van Gogh painting and 10 million non-Van Gogh\n",
    "paintings.\n",
    "\n",
    "`sklearn` is really a framework to perform machine learning problem in, not just a collection\n",
    "of machine learning models.  Data preprocessing and evaluation of the several models one create\n",
    "in the search for a good model are the strong points of the framework.  You will spend 90% of\n",
    "your time preprocessing the data and evaluating models instead of hacking model specific code,\n",
    "`sklearn` attempts to automate as much as possible of that time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "*   [Base Rate Fallacy - Statistics Done Wrong][1] \"statistics done wrong\"\n",
    "*   [TF-IDF - Introduction to Information Retrieval][2] \"document and query weighting schemes\"\n",
    "\n",
    "[1]: https://www.statisticsdonewrong.com/p-value.html\n",
    "[2]: https://nlp.stanford.edu/IR-book/html/htmledition/document-and-query-weighting-schemes-1.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
